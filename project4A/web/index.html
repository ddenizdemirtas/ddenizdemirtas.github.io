<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS180 Project 3</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>
    <div class="container">
        <nav id="sidebar">
            <h3>Contents</h3>
            <ul>
                <li><a href="#technique1">Part 1</a></li>
                <li><a href="#technique2">Part 2</a></li>
                <li><a href="#technique3">Part 3</a></li>
                <li><a href="#technique4">Part 4</a></li>

                <!-- Add more technique links as needed -->
            </ul>
        </nav>

        <main id="content">
            <div id="part1" class="section">
                <h1>CS180 Project 4: Image Warping and Mosaicing</h1>
                <h2>Deniz Demirtas</h2>

                <div class="content">
                    <p>In this project, we will leverage our learnings of image warping from the previous projects and
                        build tools that make you think it's <i>magic</i>.</p>

                    <p>Before we get started, let's remember more about image warping. Image warping refers to the
                        process of applying a spatial transformation to an image, mapping every pixel in the source
                        image to a new location in the destination image. This operation allows changes in the geometry
                        of an image, including moving, rotating, scaling, or applying a more complex deformation such as
                        perspective adjustments. The transformation can be applied in two ways: forward warp or inverse
                        warp. In a forward warp, pixels from the source image are mapped directly to new positions in
                        the destination image, which can result in gaps if some destination pixels are not assigned a
                        value. In an inverse warp, each pixel in the destination image is mapped back to the source
                        image to determine its value, ensuring complete coverage without missing pixels.

                        The goal of image warping is to modify the image such that it aligns with a different reference
                        plane, corrects distortions, or integrates seamlessly with other images, as in the case of
                        mosaicing or panorama stitching.</p>
                </div>
            </div>

            <div id="technique1" class="section">
                <h2>Homografies</h2>
                <div class="content">

                    <p>To calculate a <strong>homography</strong> matrix (<code>H</code>), we need at least <strong>four
                            pairs of corresponding points</strong> between two views of the same planar scene. A
                        homography is a <strong>3x3 projective transformation matrix</strong> that relates the
                        coordinates of points in one image to those in another image, particularly when both images are
                        taken from different viewpoints. The homography matrix (<code>H</code>) has <strong>eight
                            degrees of freedom</strong> (as it has nine elements, but one is typically fixed for
                        normalization purposes), allowing it to represent transformations like rotation, translation,
                        scaling, and perspective effects.</p>

                    <p>Intuitively, calculating a homography involves understanding the relationship between two images
                        of the same plane but captured from different angles or perspectives. The key idea is that if
                        you can find a set of corresponding points between the images, you can use these points to
                        determine how one image can be warped to match the other. This process is critical in
                        applications such as image mosaicing, where different images need to be aligned to create a
                        seamless panoramic view.</p>

                    <p>To determine the homography, you first need to identify at least four corresponding points in the
                        two images. I have picked these points manually. Once the points are identified, the
                        homography matrix can be calculated by solving a system of linear equations. This matrix
                        contains information about how the images relate to each other, including any rotations,
                        translations, scalings, and perspective changes.</p>

                    <p>Since the equations that relate the corresponding points are generally non-linear, we simplify
                        the problem by converting them into a set of linear equations. This process involves
                        cross-multiplying to eliminate the denominators, which allows us to represent the transformation
                        in a linear form. The solution to these linear equations provides the values for the elements of
                        the homography matrix.

                    <p>The final solution is typically found using a method called <strong>Singular Value Decomposition
                            (SVD)</strong>, which provides a least-squares estimate of the homography matrix. This
                        approach ensures that the solution minimizes the error across all corresponding points,
                        resulting in a transformation that best aligns the two images. By understanding the degrees of
                        freedom involved and the way these transformations are computed, we can appreciate the
                        flexibility of homographies in representing complex changes in perspective and alignment between
                        planar surfaces.</p>

                    <h3>Implementation of Homography Calculation</h3>

                    <p>The <code>computeH</code> function takes two sets of corresponding points, <code>im1_pts</code>
                        and <code>im2_pts</code>, from two images and calculates the homography matrix <code>H</code>
                        that maps points from the first image to the second. Here is the function in detail:</p>

                    <pre><code>def computeH(im1_pts, im2_pts):
                        
                            im1_pts = np.asarray(im1_pts)
                            im2_pts = np.asarray(im2_pts)
                            
                            num_points = im1_pts.shape[0]
                            
                            x1, y1 = im1_pts[:, 0], im1_pts[:, 1]
                            x2, y2 = im2_pts[:, 0], im2_pts[:, 1]
                            
                            # Empty matrix
                            A = np.zeros((2 * num_points, 9))
                            
                            # Fill in the rows of A 
                            A[0::2, 0:3] = np.stack([-x1, -y1, -np.ones(num_points)], axis=1)
                            A[0::2, 6:9] = np.stack([x2 * x1, x2 * y1, x2], axis=1)
                        
                            A[1::2, 3:6] = np.stack([-x1, -y1, -np.ones(num_points)], axis=1)
                            A[1::2, 6:9] = np.stack([y2 * x1, y2 * y1, y2], axis=1)
                        
                            U, S, Vt = np.linalg.svd(A)
                            h = Vt[-1, :] / Vt[-1, -1] 
                            
                            H = h.reshape((3, 3))
                            
                            return H</code></pre>

                    <p><strong>Step-by-Step Explanation:</strong></p>

                    <ul>

                        <li><strong>Matrix A Construction:</strong> An empty matrix <code>A</code> is created with
                            dimensions <code>(2 * num_points, 9)</code>. This matrix stores the coefficients of the
                            linear equations derived from the point correspondences. The homography calculation can be
                            formulated as a linear algebra problem. For each corresponding point pair, we derive two
                            linear equations that represent the mapping between the original and destination images.
                            Specifically, for a point <code>(x, y)</code> in the first image and a corresponding point
                            <code>(x', y')</code> in the second image, we can write down two linear equations involving
                            the unknown homography parameters. The matrix <code>A</code> collects these coefficients
                            such that we can express the entire system in the form <code>A * h = 0</code>, where
                            <code>h</code> is the vector containing all nine elements of the homography matrix
                            (flattened).
                        </li>
                        <li><strong>Filling Matrix A:</strong> The matrix <code>A</code> is filled with appropriate
                            values based on the point correspondences. Each correspondence pair contributes two rows to
                            the matrix, which encode the relationship between the coordinates in the two images. For
                            each point, we generate two equations to express the transformation: one equation for the
                            x-coordinate and one for the y-coordinate. The entries in these rows contain values derived
                            from the coordinates of the points and include terms for the elements of the homography
                            matrix. By setting up this system, we ultimately aim to solve <code>A * h = 0</code>, which
                            describes how the homography transforms points from the first image to align with the
                            corresponding points in the second image.</li>

                        <li><strong>Singular Value Decomposition (SVD):</strong> The function then performs
                            <strong>SVD</strong> on the matrix <code>A</code> to solve for <code>h</code>. The vector
                            <code>h</code> is the last row of <code>Vt</code>, which corresponds to the smallest
                            singular value, providing the best solution for minimizing the error in
                            <code>A * h = 0</code>.
                        </li>
                        <li><strong>Normalization and Reshape:</strong> The resulting vector <code>h</code> is
                            normalized by dividing by its last element to ensure scale consistency. Finally,
                            <code>h</code> is reshaped into a <code>3x3</code> matrix to form the homography
                            <code>H</code>.
                        </li>
                    </ul>

                    <p>This approach ensures that the computed homography <code>H</code> best describes the
                        transformation between the two sets of corresponding points. Using SVD helps in finding the
                        least-squares solution, making the homography calculation robust even in the presence of minor
                        noise or errors in the point correspondences.</p>
                </div>
            </div>
            <div id="technique2" class="section">
                <div class="content">
                    <h3>Warping The Image</h3>
                    <p>The process of image warping using homographies involves applying the inverse of a homography
                        matrix to an image. This technique is used to transform the perspective of an image so that it
                        aligns with a particular viewpoint or geometry. Typically, the direct application of a
                        homography warps the source image to match the destination plane. However, to accurately map the
                        destination image back to the source or to correct distortions, the inverse of the homography
                        matrix is used. This inverse transformation ensures that each pixel in the output image
                        correctly corresponds to pixels in the input image, based on the geometric projection defined by
                        the homography.</p>

                    <p>Warping an image through a homography involves computing the dot product of the homography matrix
                        with the pixel coordinates extended into homogenous form. This results in new coordinates that
                        dictate where each pixel of the transformed image will be placed. However, since these new
                        coordinates often do not align perfectly with the discrete pixel grid of the output image,
                        interpolation is necessary to determine the final pixel values. Bilinear interpolation is
                        commonly used in this context; it considers the closest four pixels of the original image to
                        estimate the pixel value at a new position by computing a weighted average, taking into account
                        the distances from each of these four surrounding pixels. This method helps in achieving
                        smoother and more visually appealing transformations.</p>

                    <p>If you are interested more on that, you can visit my previous projects for more detailed
                        breakdowns of the functions used for the above process.</p>
                </div>
            </div>
            <div id="technique3" class="section">
                <div class="content">

                    <h2>Where the <i> magic</i> starts</h2>

                    <p>Now, we get to see arguably the most interesting knowledge of my undergraduate education in
                        action as
                        we test the accuracy of our homography calculation and image warping functions. To test this, we
                        are
                        going to generate rectifications of images. This process allows us to visualize certain objects
                        that
                        we select through our correspondences, carrying the visual rays that trace through that object
                        and
                        reconstructing them on another plane to achieve a different perspective of the image.
                        Rectification
                        involves aligning the lines of sight from multiple perspectives into a common plane, typically
                        making the viewing angles perpendicular to the plane. This is achieved mathematically by solving
                        for
                        a homography that maps distorted or tilted planes into a fronto-parallel view, ideal for
                        comparing
                        or measuring physical properties.</p>

                    <p>With this capability, we are going to generate rectifications of images that mimic the scanning
                        feature of our smartphones by creating perpendicular perspective images of objects photographed
                        from
                        slanted angles. This advanced application enables us to simulate a flatbed scanner effect,
                        providing
                        clear and aligned views of objects as if viewed directly from above, which is invaluable for
                        digital
                        archiving, image analysis, and optical character recognition tasks.</p>


                    <h4>Take a Trip To Mardin, Turkiye with me</h4>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/jesus.jpg">
                            <p>Wall rug from an Assyrian Church in Mardin</p>
                        </div>
                    </div>
                    <p>Why not take a better look and appreciate it's creation more</p>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/jesus_rectified.png" style="width: 200%;">
                        </div>
                    </div>
                    <h4>Curious for chess problems from late 1300s?</h4>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/book.jpg">
                        </div>
                    </div>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/book_rectified.png" style="width: 120%;">
                        </div>
                    </div>
                    <h4>Amsterdam Naval Museum
                        <h5>Oorlog om winst, winst uit oorlog - War for profit, profit from war</h5>
                    </h4>


                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/art.jpg">
                        </div>
                    </div>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/art_rectified.jpeg" style="width: 120%;">
                        </div>
                    </div>
                </div>
            </div>

            <div id="technique5" class="section">
                <div class="content">
                    <h2>Creating The Image Mosaics: Panorama</h2>
                    <p>Now, making sure that our functions work correctly so far, we can use them to create image
                        mosaics. Instead of warping the selected object in our initial image to a representation of its
                        geometry in a perpendicular plane, this time we are going to mark the correspondence points
                        between images that have been taken from the same position (with some allowance for slight
                        movements if the images are distant) and use the correspondences to compute the homography that
                        will warp one image onto the geometry of the other. Once warped, the images are blended together
                        to create panoramic pictures.</p>

                    <p>After we have the warped image, the difference in the workflow starts when we need to create our
                        final canvas for the panorama image to avoid broadcast errors during further operations, since
                        the warped image now has a different shape than the original. We create the final canvas by
                        identifying the corner points of both the warped and the original images and then comparing
                        these points to determine the maximum canvas size required for the mosaic. After that, we apply
                        our warped and original images onto separate canvases to ensure that all subsequent operations
                        are free of broadcast errors.</p>

                    <pre><code>coords_y, coords_x = np.indices(tower1_image_warped.shape[:2])
                    
                    valid_x_mask = (coords_x >= 0) & (coords_x < canvas1.shape[1])
                    valid_y_mask = (coords_y >= 0) & (coords_y < canvas1.shape[0])
                    
                    valid_mask = valid_x_mask & valid_y_mask
                    non_black_mask = ~np.all(tower1_image_warped == [0, 0, 0], axis=-1)
                    
                    # Combine the valid mask and non-black mask to ensure only valid, non-black pixels are transferred
                    final_mask = valid_mask & non_black_mask
                    
                    # Apply the final mask to place the warped image pixels onto the canvas
                    canvas1[coords_y[final_mask], coords_x[final_mask]] = tower1_image_warped[final_mask]</code></pre>
                    <p>This code ensures that only the valid pixels from the warped image are placed onto the canvas.
                        The <code>coords_y</code> and <code>coords_x</code> arrays represent the pixel coordinates of
                        the warped image. The <code>valid_x_mask</code> and <code>valid_y_mask</code> are used to
                        identify pixels that lie within the bounds of the canvas, while <code>non_black_mask</code>
                        identifies pixels that are not black (i.e., non-zero values). The <code>final_mask</code>
                        combines these conditions, ensuring that only valid, non-black pixels are applied to the final
                        canvas, preventing any errors or unintended artifacts during the mosaic creation process.</p>

                    <p>At this point, we can create panoramic pictures with effective overlap if the correspondence
                        points are appropriately selected. However, the seam between the two images will often be
                        noticeable, making the mosaic appear less like a single, unified image. To address this, we use
                        Laplacian blending to create a smooth transition between the images. Unlike simple masking, this
                        requires an automatic and dynamic approach to create a blending mask that adapts to the specific
                        overlap region of the images.</p>

                    <p>The blending mask is automatically generated by identifying the overlapping regions between the
                        two images and then creating a gradient that smoothly transitions from one image to the other.
                        This gradient ensures that the blending area between the two images is smooth, eliminating sharp
                        edges and visible seams. The blending mask is constructed using distance transforms, which
                        calculate the distance from each pixel in the overlapping area to the boundaries of the overlap.
                        The mask is then refined to ensure smooth blending across the entire overlap, with a focus on
                        maintaining a consistent gradient transition.</p>

                    <p>Once the blending mask is created, we use it to perform Laplacian blending. The process begins
                        with the construction of Gaussian pyramids for each image, which are formed by iteratively
                        downsampling the images. These Gaussian pyramids are then used to create Laplacian pyramids by
                        subtracting an upsampled version of the next level from the current level, capturing the
                        high-frequency details. We blend the images at each level of the Laplacian pyramid using the
                        Gaussian version of our mask, and finally, we reconstruct the blended image by combining all the
                        levels. This results in a seamlessly blended panorama, where the transitions between the images
                        are smooth and natural.</p>

                    <h4>Have a look at the view with me</h4>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/tower.jpg">
                        </div>
                        <div class="image-wrapper">
                            <img src="media/tower2.jpg">
                        </div>
                    </div>
                    <p>Panorama!</p>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/tower_blend_v2_res.jpg">
                        </div>
                    </div>
                    <h4>Couch view</h4>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/mutfak1.jpg">
                        </div>
                        <div class="image-wrapper">
                            <img src="media/mutfak2.jpg">
                        </div>
                    </div>
                    <p>Panorama!</p>
                    <div class="image-container">
                        <div class="image-wrapper">
                            <img src="media/mutfak_blend.jpg">
                        </div>
                    </div>
                </div>
            </div>
    </div>

    </main>
    </div>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('#sidebar a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });

        // Fade-in animation for sections
        const sections = document.querySelectorAll('.section');
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, { threshold: 0.1 });

        sections.forEach(section => {
            observer.observe(section);
        });
    </script>

    <script>
        // JavaScript code to toggle fullscreen mode on image click
        document.addEventListener("DOMContentLoaded", function () {
            const images = document.querySelectorAll("img");
            images.forEach(function (img) {
                img.addEventListener("click", function () {
                    if (!document.fullscreenElement) {
                        // Enter full-screen mode
                        if (img.requestFullscreen) {
                            img.requestFullscreen();
                        } else if (img.webkitRequestFullscreen) { // Safari
                            img.webkitRequestFullscreen();
                        } else if (img.msRequestFullscreen) { // IE11
                            img.msRequestFullscreen();
                        }
                    } else {
                        // Exit full-screen mode
                        if (document.exitFullscreen) {
                            document.exitFullscreen();
                        } else if (document.webkitExitFullscreen) { // Safari
                            document.webkitExitFullscreen();
                        } else if (document.msExitFullscreen) { // IE11
                            document.msExitFullscreen();
                        }
                    }
                });
            });
        });
    </script>


</body>

</html>